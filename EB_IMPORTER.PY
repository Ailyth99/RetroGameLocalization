import csv
from dataclasses import dataclass
from typing import Dict, List, Tuple
from enum import Enum

@dataclass
class TextBlock:
    number: str
    start_offset: int
    end_offset: int
    jp_text: str
    cn_text: str

class TextAlignment(Enum):
    CENTER = 'center'
    LEFT = 'left'

class TranslationImporter:
    def __init__(self, encoding_file: str, alignment: TextAlignment = TextAlignment.CENTER):
        self.encoding_map: Dict[str, bytes] = {}
        self.alignment = alignment
        self.load_encoding_table(encoding_file)
        self.success_count = 0
        self.failed_blocks: List[Tuple[str, str]] = []

    def load_encoding_table(self, file_path: str):
        print("ğŸ’« æ­£åœ¨åŠ è½½ç¼–ç è¡¨...")
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) >= 2:
                    char, code = row[0], row[1]
                    self.encoding_map[char] = bytes.fromhex(code)
        print(f"âœ¨ æˆåŠŸåŠ è½½ {len(self.encoding_map)} ä¸ªå­—ç¬¦ç¼–ç ")

    def read_translation_file(self, trans_file: str) -> List[TextBlock]:
        blocks = []
        current_block = None
        
        print("ğŸ“– æ­£åœ¨è¯»å–è¯‘æ–‡æ–‡ä»¶...")
        with open(trans_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('['):
                    if current_block:
                        blocks.append(current_block)
                    
                    # è§£æå—ä¿¡æ¯
                    num = line[1:5]
                    offsets = line[7:-1].split(',')
                    start = int(offsets[0], 16)
                    end = int(offsets[1], 16)
                    current_block = TextBlock(num, start, end, "", "")
                elif line.startswith('JPï¼š'):
                    if current_block:
                        current_block.jp_text = line[3:]
                elif line.startswith('CNï¼š'):
                    if current_block:
                        current_block.cn_text = line[3:]
            
            if current_block:
                blocks.append(current_block)
                
        print(f"ğŸ“ å…±è¯»å– {len(blocks)} ä¸ªæ–‡æœ¬å—")
        return blocks

    def encode_text(self, text: str) -> Tuple[bool, bytes, str]:
        result = bytearray()
        for char in text:
            if char not in self.encoding_map:
                return False, bytes(), f"æœªæ‰¾åˆ°å­—ç¬¦ '{char}' çš„ç¼–ç "
            result.extend(self.encoding_map[char])
        return True, bytes(result), ""

    def pad_translation(self, orig_bytes: bytes, trans_bytes: bytes) -> Tuple[bool, bytes]:
        if len(trans_bytes) > len(orig_bytes) + 1:
            return False, bytes()
        
        padding_count = len(orig_bytes) - len(trans_bytes)
        if padding_count == 0:
            return True, trans_bytes
        
        result = bytearray()
        
        # æ ¹æ®å¯¹é½æ–¹å¼å†³å®šå¡«å……ä½ç½®
        if self.alignment == TextAlignment.CENTER:
            # å±…ä¸­å¯¹é½ï¼šåœ¨ä¸¤ä¾§å¡«å……ç©ºæ ¼
            left_pad = padding_count // 2
            right_pad = padding_count - left_pad
            
            result.extend([0x20] * left_pad)
            result.extend(trans_bytes)
            result.extend([0x20] * right_pad)
        else:
            # å·¦å¯¹é½ï¼šæ‰€æœ‰ç©ºæ ¼éƒ½åœ¨å³ä¾§
            result.extend(trans_bytes)
            result.extend([0x20] * padding_count)
        
        return True, bytes(result)

    def import_translations(self, trans_file: str, target_file: str):
        blocks = self.read_translation_file(trans_file)
        
        print("\nğŸš€ å¼€å§‹å¯¼å…¥è¯‘æ–‡...")
        with open(target_file, 'rb+') as f:
            for block in blocks:
                if not block.cn_text:  # è·³è¿‡æœªç¿»è¯‘çš„å—
                    continue
                    
                # è¯»å–åŸæ–‡
                f.seek(block.start_offset)
                original = f.read(block.end_offset - block.start_offset)
                
                # ç¼–ç è¯‘æ–‡
                success, encoded_text, error = self.encode_text(block.cn_text)
                if not success:
                    self.failed_blocks.append((block.number, error))
                    print(f"\nâš ï¸ å— {block.number} å¯¼å…¥å¤±è´¥: {error}")
                    continue
                
                # å¡«å……å¤„ç†
                success, padded_text = self.pad_translation(original, encoded_text)
                if not success:
                    self.failed_blocks.append((block.number, "è¯‘æ–‡é•¿åº¦è¶…è¿‡åŸæ–‡"))
                    print(f"\nâš ï¸ å— {block.number} å¯¼å…¥å¤±è´¥: è¯‘æ–‡è¿‡é•¿")
                    continue
                
                # å†™å…¥è¯‘æ–‡
                f.seek(block.start_offset)
                f.write(padded_text)
                self.success_count += 1
                print(f"\râœ¨ å·²æˆåŠŸå¯¼å…¥ {self.success_count} ä¸ªæ–‡æœ¬å—...", end='')

        print("\n\nğŸ“Š å¯¼å…¥ç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸå¯¼å…¥: {self.success_count} ä¸ªæ–‡æœ¬å—")
        print(f"âŒ å¯¼å…¥å¤±è´¥: {len(self.failed_blocks)} ä¸ªæ–‡æœ¬å—")
        
        if self.failed_blocks:
            print("\nâš ï¸ å¤±è´¥è¯¦æƒ…:")
            for num, reason in self.failed_blocks:
                print(f"  å— {num}: {reason}")

def main():
    print("ğŸŒŸ æ–‡æœ¬å¯¼å…¥å·¥å…·å¯åŠ¨")
    
    # å¯ä»¥åœ¨è¿™é‡ŒæŒ‡å®šå¯¹é½æ–¹å¼
    ENCODE_FILE = r'TEMP\tbl.csv'
    TRANSLATION_FILE = r'SCRIPT\EB\EV849.txt'
    TARGET_FILE = r'SCRIPT\EB\EV849.EB'
    ALIGNMENT = TextAlignment.CENTER
    #ALIGNMENT = TextAlignment.CENTER
    print(f"ğŸ“ TARGET_FILE: {TARGET_FILE} æ–‡æœ¬å¯¹é½æ–¹å¼: {ALIGNMENT.value}")
    
    importer = TranslationImporter(ENCODE_FILE, ALIGNMENT)
    importer.import_translations(TRANSLATION_FILE, TARGET_FILE)

if __name__ == "__main__":
    main()